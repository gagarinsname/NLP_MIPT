{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aliases = pd.read_csv('data/Aliases.csv')\n",
    "emailreceivers = pd.read_csv('data/EmailReceivers.csv')\n",
    "emails = pd.read_csv('data/Emails.csv')\n",
    "persons = pd.read_csv('data/Persons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'DocNumber', 'MetadataSubject', 'MetadataTo', 'MetadataFrom',\n",
       "       'SenderPersonId', 'MetadataDateSent', 'MetadataDateReleased',\n",
       "       'MetadataPdfLink', 'MetadataCaseNumber', 'MetadataDocumentClass',\n",
       "       'ExtractedSubject', 'ExtractedTo', 'ExtractedFrom', 'ExtractedCc',\n",
       "       'ExtractedDateSent', 'ExtractedCaseNumber', 'ExtractedDocNumber',\n",
       "       'ExtractedDateReleased', 'ExtractedReleaseInPartOrFull',\n",
       "       'ExtractedBodyText', 'RawText'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(emails[['MetadataSubject', 'ExtractedBodyText']])\n",
    "data.columns = ['subject', 'body']\n",
    "data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOW</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>Thx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAIRO CONDEMNATION - FINAL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\nFriday, March 11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEET THE RIGHT-WING EXTREMIST BEHIND ANTI-MUSL...</td>\n",
       "      <td>Pis print.\\n-•-...-^\\nH &lt; hrod17@clintonernail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ANTI-MUSLIM FILM DIRECTOR IN HIDING, FOLLOWING...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H &lt;hrod17@clintonemail.corn&gt;\\nFriday, March 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SECRETARY'S REMARKS</td>\n",
       "      <td>FYI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MORE ON LIBYA</td>\n",
       "      <td>B6\\nWednesday, September 12, 2012 6:16 PM\\nFwd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ABZ AN HBJ ON LIBYA AND WEST BANK/GAZA</td>\n",
       "      <td>Fyi\\nB6\\n— —</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MORE ON LIBYA</td>\n",
       "      <td>B6\\nWednesday, September 12, 2012 6:16 PM\\nFwd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HEY</td>\n",
       "      <td>Fyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PIECE ON LIBYA NFZ THAT WILL APPEAR ON NYT OP-...</td>\n",
       "      <td>Anne-Marie Slaughter\\nSunday, March 13, 2011 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NOT A DRY EYE IN NEA</td>\n",
       "      <td>_ .....\\nFrom Randolph, Lawrence M\\nSent: Wedn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>THANK YOU</td>\n",
       "      <td>I asked to attend your svtc today with Embassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>THE YOUTH OF LIBYA</td>\n",
       "      <td>Hope. See picture below Kamala sent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ONE MORE PHOTO</td>\n",
       "      <td>Another photo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S TODAY</td>\n",
       "      <td>This is nice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>THE YOUTH OF LIBYA</td>\n",
       "      <td>Amazing.\\nSullivan, Jacob J &lt;Sullivanii@state,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              subject  \\\n",
       "0                                                 WOW   \n",
       "1   H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "2                                       CHRIS STEVENS   \n",
       "3                          CAIRO CONDEMNATION - FINAL   \n",
       "4   H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "5   MEET THE RIGHT-WING EXTREMIST BEHIND ANTI-MUSL...   \n",
       "6   ANTI-MUSLIM FILM DIRECTOR IN HIDING, FOLLOWING...   \n",
       "7   H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "8                                 SECRETARY'S REMARKS   \n",
       "9                                       MORE ON LIBYA   \n",
       "10             ABZ AN HBJ ON LIBYA AND WEST BANK/GAZA   \n",
       "11                                      MORE ON LIBYA   \n",
       "12                                                HEY   \n",
       "13  PIECE ON LIBYA NFZ THAT WILL APPEAR ON NYT OP-...   \n",
       "14                               NOT A DRY EYE IN NEA   \n",
       "15                                          THANK YOU   \n",
       "16                                 THE YOUTH OF LIBYA   \n",
       "17                                     ONE MORE PHOTO   \n",
       "18                                            S TODAY   \n",
       "19                                 THE YOUTH OF LIBYA   \n",
       "\n",
       "                                                 body  \n",
       "0                                                      \n",
       "1   B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...  \n",
       "2                                                 Thx  \n",
       "3                                                      \n",
       "4   H <hrod17@clintonemail.com>\\nFriday, March 11,...  \n",
       "5   Pis print.\\n-•-...-^\\nH < hrod17@clintonernail...  \n",
       "6                                                      \n",
       "7   H <hrod17@clintonemail.corn>\\nFriday, March 11...  \n",
       "8                                                 FYI  \n",
       "9   B6\\nWednesday, September 12, 2012 6:16 PM\\nFwd...  \n",
       "10                                       Fyi\\nB6\\n— —  \n",
       "11  B6\\nWednesday, September 12, 2012 6:16 PM\\nFwd...  \n",
       "12                                                Fyi  \n",
       "13  Anne-Marie Slaughter\\nSunday, March 13, 2011 9...  \n",
       "14  _ .....\\nFrom Randolph, Lawrence M\\nSent: Wedn...  \n",
       "15  I asked to attend your svtc today with Embassy...  \n",
       "16               Hope. See picture below Kamala sent.  \n",
       "17                                     Another photo.  \n",
       "18                                      This is nice.  \n",
       "19  Amazing.\\nSullivan, Jacob J <Sullivanii@state,...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка и анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработаем сперва темы писем. В них содержатся шумовые токены вроде \"FWD:\" или \"Re:\". Избавимся от них с помощью регулярных выражений.\n",
    "Затем предобработаем тексты писем, в которых также содержатся шумовые строки, начинающиеся с подстрок \"Re:\" или \"H:\". Стоит также удалить шумовые тэги, такие как \"From:\", штампы \"U.S. Department...\", отметки времени и/или даты. Также удалим строки с номерами документов вроде \"Case No\" и строки с числами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def is_date(string):\n",
    "    try:\n",
    "        parse(string)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def has_numbers(string):\n",
    "    return bool(re.search(r'\\d', string))\n",
    "\n",
    "def process_body(elem):\n",
    "    lines = elem.splitlines()\n",
    "    trashpattern = re.compile(r\"^(Doc No\\\\..*|Case No\\\\.|H <.*@.*>|.*@.*|From .|To:.|For:.*|Subject:.|U.S. Department of State$)\")\n",
    "    datepattern = re.compile(r\"Date: \\d{2}/\\d{2}/\\d{4}\")\n",
    "    timepattern = re.compile(r\".*\\d{1,2}:(\\d{2}\\s(?:AM|PM))\")\n",
    "    keypattern = re.compile(r\"\\s*(Fwd|Fw|Fvv|FVV|FW|Re|re|RE|H):\\s*\")\n",
    "    numpattern = re.compile(r\".*(\\d*-\\d*|\\d+\\b).*\")\n",
    "    lines = list(filter(lambda line: not datepattern.match(line) and not trashpattern.match(line) and not keypattern.match(line)\n",
    "            and not timepattern.match(line) and not numpattern.match(line),lines))\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def process_subject(elem):\n",
    "    if elem == '':\n",
    "        return elem\n",
    "    keypattern = r's*(Fwd|Fw|Fvv|FVV|FW|Re|re|RE|H):\\s*'\n",
    "    subject = re.sub(keypattern, \"\", elem)\n",
    "    subject = re.sub(keypattern, \"\", elem)\n",
    "    return subject\n",
    "\n",
    "data['subjectProc'] = data.subject.apply(process_subject)\n",
    "data['bodyProc'] = data.body.apply(process_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>subjectProc</th>\n",
       "      <th>bodyProc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOW</td>\n",
       "      <td></td>\n",
       "      <td>WOW</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...</td>\n",
       "      <td>LATEST: HOW SYRIA IS AIDING QADDAFI AND MORE.....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>Thx</td>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>Thx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAIRO CONDEMNATION - FINAL</td>\n",
       "      <td></td>\n",
       "      <td>CAIRO CONDEMNATION - FINAL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\nFriday, March 11,...</td>\n",
       "      <td>LATEST: HOW SYRIA IS AIDING QADDAFI AND MORE.....</td>\n",
       "      <td>Huma Abedin\\nPis print.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEET THE RIGHT-WING EXTREMIST BEHIND ANTI-MUSL...</td>\n",
       "      <td>Pis print.\\n-•-...-^\\nH &lt; hrod17@clintonernail...</td>\n",
       "      <td>MEET THE RIGHT-WING EXTREMIST BEHIND ANTI-MUSL...</td>\n",
       "      <td>Pis print.\\nSent from my Verizon Wireless 4G L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ANTI-MUSLIM FILM DIRECTOR IN HIDING, FOLLOWING...</td>\n",
       "      <td></td>\n",
       "      <td>ANTI-MUSLIM FILM DIRECTOR IN HIDING, FOLLOWING...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H &lt;hrod17@clintonemail.corn&gt;\\nFriday, March 11...</td>\n",
       "      <td>LATEST: HOW SYRIA IS AIDING QADDAFI AND MORE.....</td>\n",
       "      <td>Huma Abedin\\nPis print.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SECRETARY'S REMARKS</td>\n",
       "      <td>FYI</td>\n",
       "      <td>SECRETARY'S REMARKS</td>\n",
       "      <td>FYI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MORE ON LIBYA</td>\n",
       "      <td>B6\\nWednesday, September 12, 2012 6:16 PM\\nFwd...</td>\n",
       "      <td>MORE ON LIBYA</td>\n",
       "      <td>Sending direct. Just in.\\nSent from my Verizon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ABZ AN HBJ ON LIBYA AND WEST BANK/GAZA</td>\n",
       "      <td>Fyi\\nB6\\n— —</td>\n",
       "      <td>ABZ AN HBJ ON LIBYA AND WEST BANK/GAZA</td>\n",
       "      <td>Fyi\\n— —</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MORE ON LIBYA</td>\n",
       "      <td>B6\\nWednesday, September 12, 2012 6:16 PM\\nFwd...</td>\n",
       "      <td>MORE ON LIBYA</td>\n",
       "      <td>Sending direct. Just in.\\nSent from my Verizon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HEY</td>\n",
       "      <td>Fyi</td>\n",
       "      <td>HEY</td>\n",
       "      <td>Fyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PIECE ON LIBYA NFZ THAT WILL APPEAR ON NYT OP-...</td>\n",
       "      <td>Anne-Marie Slaughter\\nSunday, March 13, 2011 9...</td>\n",
       "      <td>PIECE ON LIBYA NFZ THAT WILL APPEAR ON NYT OP-...</td>\n",
       "      <td>wanted to make sure you had a heads up. AM\\nti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NOT A DRY EYE IN NEA</td>\n",
       "      <td>_ .....\\nFrom Randolph, Lawrence M\\nSent: Wedn...</td>\n",
       "      <td>NOT A DRY EYE IN NEA</td>\n",
       "      <td>_ .....\\nIncluding mine. Her remarks were real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>THANK YOU</td>\n",
       "      <td>I asked to attend your svtc today with Embassy...</td>\n",
       "      <td>THANK YOU</td>\n",
       "      <td>I asked to attend your svtc today with Embassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>THE YOUTH OF LIBYA</td>\n",
       "      <td>Hope. See picture below Kamala sent.</td>\n",
       "      <td>THE YOUTH OF LIBYA</td>\n",
       "      <td>Hope. See picture below Kamala sent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ONE MORE PHOTO</td>\n",
       "      <td>Another photo.</td>\n",
       "      <td>ONE MORE PHOTO</td>\n",
       "      <td>Another photo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S TODAY</td>\n",
       "      <td>This is nice.</td>\n",
       "      <td>S TODAY</td>\n",
       "      <td>This is nice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>THE YOUTH OF LIBYA</td>\n",
       "      <td>Amazing.\\nSullivan, Jacob J &lt;Sullivanii@state,...</td>\n",
       "      <td>THE YOUTH OF LIBYA</td>\n",
       "      <td>Amazing.\\nSherman, Wendy R; H; Mills, Cheryl D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              subject  \\\n",
       "0                                                 WOW   \n",
       "1   H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "2                                       CHRIS STEVENS   \n",
       "3                          CAIRO CONDEMNATION - FINAL   \n",
       "4   H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "5   MEET THE RIGHT-WING EXTREMIST BEHIND ANTI-MUSL...   \n",
       "6   ANTI-MUSLIM FILM DIRECTOR IN HIDING, FOLLOWING...   \n",
       "7   H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "8                                 SECRETARY'S REMARKS   \n",
       "9                                       MORE ON LIBYA   \n",
       "10             ABZ AN HBJ ON LIBYA AND WEST BANK/GAZA   \n",
       "11                                      MORE ON LIBYA   \n",
       "12                                                HEY   \n",
       "13  PIECE ON LIBYA NFZ THAT WILL APPEAR ON NYT OP-...   \n",
       "14                               NOT A DRY EYE IN NEA   \n",
       "15                                          THANK YOU   \n",
       "16                                 THE YOUTH OF LIBYA   \n",
       "17                                     ONE MORE PHOTO   \n",
       "18                                            S TODAY   \n",
       "19                                 THE YOUTH OF LIBYA   \n",
       "\n",
       "                                                 body  \\\n",
       "0                                                       \n",
       "1   B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...   \n",
       "2                                                 Thx   \n",
       "3                                                       \n",
       "4   H <hrod17@clintonemail.com>\\nFriday, March 11,...   \n",
       "5   Pis print.\\n-•-...-^\\nH < hrod17@clintonernail...   \n",
       "6                                                       \n",
       "7   H <hrod17@clintonemail.corn>\\nFriday, March 11...   \n",
       "8                                                 FYI   \n",
       "9   B6\\nWednesday, September 12, 2012 6:16 PM\\nFwd...   \n",
       "10                                       Fyi\\nB6\\n— —   \n",
       "11  B6\\nWednesday, September 12, 2012 6:16 PM\\nFwd...   \n",
       "12                                                Fyi   \n",
       "13  Anne-Marie Slaughter\\nSunday, March 13, 2011 9...   \n",
       "14  _ .....\\nFrom Randolph, Lawrence M\\nSent: Wedn...   \n",
       "15  I asked to attend your svtc today with Embassy...   \n",
       "16               Hope. See picture below Kamala sent.   \n",
       "17                                     Another photo.   \n",
       "18                                      This is nice.   \n",
       "19  Amazing.\\nSullivan, Jacob J <Sullivanii@state,...   \n",
       "\n",
       "                                          subjectProc  \\\n",
       "0                                                 WOW   \n",
       "1   LATEST: HOW SYRIA IS AIDING QADDAFI AND MORE.....   \n",
       "2                                       CHRIS STEVENS   \n",
       "3                          CAIRO CONDEMNATION - FINAL   \n",
       "4   LATEST: HOW SYRIA IS AIDING QADDAFI AND MORE.....   \n",
       "5   MEET THE RIGHT-WING EXTREMIST BEHIND ANTI-MUSL...   \n",
       "6   ANTI-MUSLIM FILM DIRECTOR IN HIDING, FOLLOWING...   \n",
       "7   LATEST: HOW SYRIA IS AIDING QADDAFI AND MORE.....   \n",
       "8                                 SECRETARY'S REMARKS   \n",
       "9                                       MORE ON LIBYA   \n",
       "10             ABZ AN HBJ ON LIBYA AND WEST BANK/GAZA   \n",
       "11                                      MORE ON LIBYA   \n",
       "12                                                HEY   \n",
       "13  PIECE ON LIBYA NFZ THAT WILL APPEAR ON NYT OP-...   \n",
       "14                               NOT A DRY EYE IN NEA   \n",
       "15                                          THANK YOU   \n",
       "16                                 THE YOUTH OF LIBYA   \n",
       "17                                     ONE MORE PHOTO   \n",
       "18                                            S TODAY   \n",
       "19                                 THE YOUTH OF LIBYA   \n",
       "\n",
       "                                             bodyProc  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                 Thx  \n",
       "3                                                      \n",
       "4                             Huma Abedin\\nPis print.  \n",
       "5   Pis print.\\nSent from my Verizon Wireless 4G L...  \n",
       "6                                                      \n",
       "7                             Huma Abedin\\nPis print.  \n",
       "8                                                 FYI  \n",
       "9   Sending direct. Just in.\\nSent from my Verizon...  \n",
       "10                                           Fyi\\n— —  \n",
       "11  Sending direct. Just in.\\nSent from my Verizon...  \n",
       "12                                                Fyi  \n",
       "13  wanted to make sure you had a heads up. AM\\nti...  \n",
       "14  _ .....\\nIncluding mine. Her remarks were real...  \n",
       "15  I asked to attend your svtc today with Embassy...  \n",
       "16               Hope. See picture below Kamala sent.  \n",
       "17                                     Another photo.  \n",
       "18                                      This is nice.  \n",
       "19  Amazing.\\nSherman, Wendy R; H; Mills, Cheryl D...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7945\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Биграммы из текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopset = list(stopwords.words('english')) + [\"'s\"] + [\"n't\"] + ['']\n",
    "punctset = string.punctuation + '—' + '`' + \"'\" + \"•\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenset = list(list(filter(lambda token: token.lower() not in stopset and token not in punctset, word_tokenize(line)))\n",
    "              for index, text in data.bodyProc.iteritems() for line in text.splitlines())\n",
    "tokenset = list(list(\"\".join(l for l in list(filter(lambda c: c not in punctset, token))) for token in doc)\n",
    "               for doc in tokenset)\n",
    "bigrams = list(bg for elem in tokenset for bg in list(ngrams(elem,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35448\n",
      "['retaken', 'least', 'besieged', 'Benghazi', 'opposition', 'stronghold']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenset))\n",
    "print(tokenset[55])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем 5 наиболее часто встречающихся биграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "frequencies = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('United', 'States'), 325), (('White', 'House'), 239), (('Secretary', 'State'), 147), (('New', 'York'), 140), (('State', 'Department'), 134)]\n"
     ]
    }
   ],
   "source": [
    "print(frequencies.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Биграммы с помощью NLTK по PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "tokens = [token for tokens in tokenset for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('United', 'States'), ('White', 'House')]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_fd = nltk.FreqDist(tokens)\n",
    "bigram_fd = nltk.FreqDist(nltk.bigrams(tokens))\n",
    "finder = BigramCollocationFinder(word_fd, bigram_fd)\n",
    "sorted(finder.nbest(bigram_measures.raw_freq, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183003"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finder.score_ngrams(bigram_measures.raw_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder.apply_word_filter(lambda w: w.lower() in stopset + [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180591"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finder.score_ngrams(bigram_measures.raw_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(finder.above_score(bigram_measures.raw_freq, 1.0 / len(tuple(nltk.bigrams(tokens)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('United', 'States'), ('White', 'House')]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(finder.nbest(bigram_measures.raw_freq, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили те же наиболее часто встречающиеся биграммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, text in data.bodyProc.iteritems() for line in text.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация писем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = list(text.lower().replace('\\n', '') for index, text in data.bodyProc.iteritems())\n",
    "preproc_texts = list(' '.join(elem for elem in list(filter(lambda token: token not in stopset, word_tokenize(text))))\n",
    "                     for text in texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc_texts = list(''.join(elem for elem in list(filter(lambda c: c not in punctset, list(text)))) for text in preproc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = list(texts[55].lower())\n",
    "# for c in list(punctset):\n",
    "#     res = res.replace(c,'')\n",
    "print(res)\n",
    "#print(set(res.split(' ')) - set(stopset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=500, min_df=10)\n",
    "object_feature = vectorizer.fit_transform(preproc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7945, 2844)\n"
     ]
    }
   ],
   "source": [
    "print(object_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dbscan\n",
    "# Latent Dirichlet Allocation?? -> sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Аггломеративная кластеризация (neighbour joining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster.hierarchical import AgglomerativeClustering\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=20, affinity='euclidean', linkage='complete')\n",
    "preds = model.fit_predict(object_feature.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=3, random_state=1)\n",
    "preds = model.fit_predict(object_feature.toarray())\n",
    "print(preds[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## target value??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD + KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "svd = TruncatedSVD(n_components=1000, random_state=123)\n",
    "features = svd.fit_transform(object_feature)\n",
    "preds = model.fit_predict(features)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for elem in word_tokenize(str(texts[1])):\n",
    "    print(elem, ps.stem(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for elem in texts:\n",
    "    X.append(word_tokenize(elem))\n",
    "    for j in range(len(X[i])):\n",
    "        X[i][j] = PorterStemmer().stem(X[i][j])\n",
    "    X[i] = \" \".join(X[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
