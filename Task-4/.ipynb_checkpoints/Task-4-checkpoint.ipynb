{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning for Natural Language Processing\n",
    "\n",
    "* Simple text representations, bag of words\n",
    "* Word embedding and... not just another word2vec this time rnn for text\n",
    "* Aggregating several data sources \"the hard way\"\n",
    "* Solving ~somewhat~ real ML problem with ~almost~ end-to-end deep learning\n",
    "\n",
    "Special thanks to Irina Golzmann for help with technical part, task prepared by Александр Панин, jheuristic@yandex-team.ru\n",
    "NLTK\n",
    "\n",
    "You will require nltk v3.2 to solve this assignment\n",
    "\n",
    "It is really important that the version is 3.2, otherwize russian tokenizer might not work\n",
    "\n",
    "## Install/update\n",
    "\n",
    "* sudo pip install --upgrade nltk==3.2\n",
    "* If you don't remember when was the last pip upgrade, sudo pip install --upgrade pip\n",
    "\n",
    "If for some reason you can't or won't switch to nltk v3.2, just make sure that russian words are tokenized properly with RegeExpTokenizer.\n",
    "\n",
    "## For students with low-RAM machines\n",
    "\n",
    "* This assignment can be accomplished with even the low-tier hardware (<= 4Gb RAM)\n",
    "* If that is the case, turn flag \"low_RAM_mode\" below to True\n",
    "* If you have around 8GB memory, it is unlikely that you will feel constrained by memory.\n",
    "* In case you are using a PC from last millenia, consider setting very_low_RAM=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_RAM_mode = True\n",
    "very_low_RAM = False  #If you have <3GB RAM, set BOTH to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Ex-kaggle-competition on prohibited content detection\n",
    "There goes the description - https://www.kaggle.com/c/avito-prohibited-content\n",
    "\n",
    "### Download\n",
    "\n",
    "High-RAM mode,\n",
    "* Download avito_train.tsv from competition data files Low-RAM-mode,\n",
    "* Download downsampled dataset from here\n",
    "    * archive https://yadi.sk/d/l0p4lameqw3W8\n",
    "    * raw https://yadi.sk/d/I1v7mZ6Sqw2WK (in case you feel masochistic)\n",
    "\n",
    "## What's inside\n",
    "\n",
    "Different kinds of features:\n",
    "\n",
    "* 2 text fields - title and description\n",
    "* Special features - price, number of e-mails, phones, etc\n",
    "* Category and subcategory - unsurprisingly, categorical features\n",
    "* Attributes - more factors\n",
    "\n",
    "Only 1 binary target whether or not such advertisement contains prohibited materials\n",
    "\n",
    "* criminal, misleading, human reproduction-related, etc\n",
    "* diving into the data may result in prolonged sleep disorders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not low_RAM_mode:\n",
    "    # a lot of ram\n",
    "    df = pd.read_csv(\"avito_train.tsv\",sep='\\t')\n",
    "else:\n",
    "    #aroung 4GB ram\n",
    "    df = pd.read_csv(\"../../avito_train_1kk.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1204949, 13) 0.228222107326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000010</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Toyota Sera, 1991</td>\n",
       "      <td>Новая оригинальная линзованая оптика на ксенон...</td>\n",
       "      <td>{\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000094</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Костюм Steilmann</td>\n",
       "      <td>Юбка и топ из панбархата. Под топ  трикотажная...</td>\n",
       "      <td>{\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000299</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>Костюм Didriksons Boardman, размер 100, краги,...</td>\n",
       "      <td>Костюм Didriksons Boardman, в отличном состоян...</td>\n",
       "      <td>{\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000309</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>Квартиры</td>\n",
       "      <td>1-к квартира, 44 м², 9/20 эт.</td>\n",
       "      <td>В кирпичном пан.-м доме, продается одноком.-ая...</td>\n",
       "      <td>{\"Тип объявления\":\"Продам\", \"Количество комнат...</td>\n",
       "      <td>2642020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000317</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложения услуг</td>\n",
       "      <td>Поездки на таможню, печать в паспорте</td>\n",
       "      <td>Поездки на таможню гражданам СНГ для пересечен...</td>\n",
       "      <td>{\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid      category                subcategory  \\\n",
       "0  10000010     Транспорт      Автомобили с пробегом   \n",
       "1  10000094   Личные вещи  Одежда, обувь, аксессуары   \n",
       "2  10000299   Личные вещи     Детская одежда и обувь   \n",
       "3  10000309  Недвижимость                   Квартиры   \n",
       "4  10000317        Услуги          Предложения услуг   \n",
       "\n",
       "                                               title  \\\n",
       "0                                  Toyota Sera, 1991   \n",
       "1                                   Костюм Steilmann   \n",
       "2  Костюм Didriksons Boardman, размер 100, краги,...   \n",
       "3                      1-к квартира, 44 м², 9/20 эт.   \n",
       "4              Поездки на таможню, печать в паспорте   \n",
       "\n",
       "                                         description  \\\n",
       "0  Новая оригинальная линзованая оптика на ксенон...   \n",
       "1  Юбка и топ из панбархата. Под топ  трикотажная...   \n",
       "2  Костюм Didriksons Boardman, в отличном состоян...   \n",
       "3  В кирпичном пан.-м доме, продается одноком.-ая...   \n",
       "4  Поездки на таможню гражданам СНГ для пересечен...   \n",
       "\n",
       "                                               attrs    price  is_proved  \\\n",
       "0  {\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...   150000        NaN   \n",
       "1  {\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...     1500        NaN   \n",
       "2  {\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...     3000        NaN   \n",
       "3  {\"Тип объявления\":\"Продам\", \"Количество комнат...  2642020        NaN   \n",
       "4  {\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...     1500        0.0   \n",
       "\n",
       "   is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "0           0           0           0         0         0.03  \n",
       "1           0           0           0         0         0.41  \n",
       "2           0           0           0         0         5.49  \n",
       "3           0           1           0         0        22.47  \n",
       "4           1           0           0         0         1.43  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape, df.is_blocked.mean())\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio 0.228222107326\n",
      "Count: 1204949\n"
     ]
    }
   ],
   "source": [
    "print(\"Blocked ratio\",df.is_blocked.mean())\n",
    "print(\"Count:\",len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Balance-out the classes\n",
    "\n",
    "* Vast majority of data samples are non-prohibited\n",
    "    * 250k banned out of 4kk\n",
    "    * Let's just downsample random 250k legal samples to make further steps less computationally demanding\n",
    "    * If you aim for high Kaggle score, consider a smarter approach to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_subc(data):\n",
    "    # subc = '\\n'.join([cat for cat in data.subcategory.unique()])\n",
    "    return pd.Series(data.subcategory.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category              \n",
      "Бытовая электроника  0                   Аудио и видео\n",
      "                     1                        Телефоны\n",
      "                     2    Планшеты и электронные книги\n",
      "                     3     Игры, приставки и программы\n",
      "                     4         Оргтехника и расходники\n",
      "                     5           Товары для компьютера\n",
      "                     6                        Ноутбуки\n",
      "                     7           Настольные компьютеры\n",
      "                     8                     Фототехника\n",
      "Для бизнеса          0        Оборудование для бизнеса\n",
      "                     1                Продукты питания\n",
      "                     2                  Готовый бизнес\n",
      "Для дома и дачи      0               Мебель и интерьер\n",
      "                     1          Ремонт и строительство\n",
      "                     2                 Бытовая техника\n",
      "                     3       Посуда и товары для кухни\n",
      "                     4                        Растения\n",
      "                     5                Продукты питания\n",
      "Животные             0                        Аквариум\n",
      "                     1                          Собаки\n",
      "                     2                           Кошки\n",
      "                     3                 Другие животные\n",
      "                     4                           Птицы\n",
      "                     5             Товары для животных\n",
      "Личные вещи          0       Одежда, обувь, аксессуары\n",
      "                     1          Детская одежда и обувь\n",
      "                     2                Часы и украшения\n",
      "                     3              Красота и здоровье\n",
      "                     4      Товары для детей и игрушки\n",
      "Недвижимость         0                        Квартиры\n",
      "                     1                         Комнаты\n",
      "                     2       Коммерческая недвижимость\n",
      "                     3            Гаражи и машиноместа\n",
      "                     4            Дома, дачи, коттеджи\n",
      "                     5               Земельные участки\n",
      "                     6         Недвижимость за рубежом\n",
      "Работа               0                        Вакансии\n",
      "                     1                          Резюме\n",
      "Транспорт            0           Автомобили с пробегом\n",
      "                     1           Запчасти и аксессуары\n",
      "                     2         Грузовики и спецтехника\n",
      "                     3                Новые автомобили\n",
      "                     4         Мотоциклы и мототехника\n",
      "                     5                Водный транспорт\n",
      "Услуги               0               Предложения услуг\n",
      "                     1               Запросы на услуги\n",
      "Хобби и отдых        0            Билеты и путешествия\n",
      "                     1                 Охота и рыбалка\n",
      "                     2                   Спорт и отдых\n",
      "                     3              Коллекционирование\n",
      "                     4                      Знакомства\n",
      "                     5         Музыкальные инструменты\n",
      "                     6                 Книги и журналы\n",
      "                     7                      Велосипеды\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_groups = df.groupby('category', sort=False)\n",
    "print(df_groups.apply(print_subc).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Бытовая электроника      7510\n",
      "Для бизнеса             13011\n",
      "Для дома и дачи          6899\n",
      "Животные                 3349\n",
      "Личные вещи             23440\n",
      "Недвижимость             1427\n",
      "Работа                  19843\n",
      "Транспорт               18036\n",
      "Услуги                 124402\n",
      "Хобби и отдых           57079\n",
      "dtype: int64\n",
      "category\n",
      "Бытовая электроника     93621\n",
      "Для бизнеса             13509\n",
      "Для дома и дачи         54399\n",
      "Животные                29027\n",
      "Личные вещи            144348\n",
      "Недвижимость           286351\n",
      "Работа                  57934\n",
      "Транспорт              167078\n",
      "Услуги                  48623\n",
      "Хобби и отдых           35063\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ans = [bool(1-r[1]) for r in df.is_blocked.iteritems()]\n",
    "df_0 = df[ans]\n",
    "\n",
    "ans = [bool(r[1]) for r in df.is_blocked.iteritems()]\n",
    "df_1 = df[ans]\n",
    "divisor = len(df_1)\n",
    "\n",
    "def countCategory(data):\n",
    "    return len(data.category)\n",
    "\n",
    "df_groups = df_1.groupby('category', sort=False)\n",
    "blockedCatNum = df_groups.apply(countCategory).sort_index()\n",
    "notBlockedCatNum = df_0.groupby('category', sort=False).apply(countCategory).sort_index()\n",
    "print(blockedCatNum)\n",
    "print(notBlockedCatNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## A simple approach\\ndef filterData(data):\\n    subSize = len(data)\\n    categoryName = data.category.iloc[0]\\n    is_blocked = bool(data.is_blocked.iloc[0])\\n    if not is_blocked:\\n        sampleSize = blockedCatNum[categoryName]\\n        if subSize >= sampleSize:\\n            data = data.sample(sampleSize, random_state=0)\\n    return data\\n\\ndf_groups = df.groupby([\\'category\\', \\'is_blocked\\'], sort=False, as_index=False)\\nres = df_groups.apply(filterData)\\naddition = df_0.sample(residual, random_state=0)\\nres = pd.concat([res, addition])\\n\\nprint(residual)\\nprint(\"Blocked ratio:\",res.is_blocked.mean())\\nprint(\"Count:\",len(res))\\n'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## A simple approach\n",
    "def filterData(data):\n",
    "    subSize = len(data)\n",
    "    categoryName = data.category.iloc[0]\n",
    "    is_blocked = bool(data.is_blocked.iloc[0])\n",
    "    if not is_blocked:\n",
    "        sampleSize = blockedCatNum[categoryName]\n",
    "        if subSize >= sampleSize:\n",
    "            data = data.sample(sampleSize, random_state=0)\n",
    "    return data\n",
    "\n",
    "df_groups = df.groupby(['category', 'is_blocked'], sort=False, as_index=False)\n",
    "res = df_groups.apply(filterData)\n",
    "addition = df_0.sample(residual, random_state=0)\n",
    "res = pd.concat([res, addition])\n",
    "\n",
    "print(residual)\n",
    "print(\"Blocked ratio:\",res.is_blocked.mean())\n",
    "print(\"Count:\",len(res))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio: 0.503617860197\n",
      "Count: 546041\n"
     ]
    }
   ],
   "source": [
    "# A randomized approach, very naive though\n",
    "from numpy.random import poisson\n",
    "\n",
    "def filterData(data):\n",
    "    subSize = len(data)\n",
    "    categoryName = data.category.iloc[0]\n",
    "    is_blocked = bool(data.is_blocked.iloc[0])\n",
    "    if not is_blocked:\n",
    "        sampleSize = blockedCatNum[categoryName]\n",
    "        if subSize >= sampleSize:\n",
    "            sigma = (subSize - sampleSize) // 8 # MAGIC NUMBER\n",
    "            data = data.sample(sampleSize + poisson(sigma), random_state=0)\n",
    "    return data\n",
    "\n",
    "df_groups = df.groupby(['category', 'is_blocked'], sort=False, as_index=False)\n",
    "res = df_groups.apply(filterData)\n",
    "\n",
    "print(\"Blocked ratio:\",res.is_blocked.mean())\n",
    "print(\"Count:\",len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio: 0.503617860197\n",
      "Count: 546041\n"
     ]
    }
   ],
   "source": [
    "#downsample\n",
    "\n",
    "## use categories\n",
    "\n",
    "# < downsample data so that both classes have approximately equal ratios>\n",
    "\n",
    "# df = <downsampled dataset>\n",
    "df = res.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"Blocked ratio:\",df.is_blocked.mean())\n",
    "print(\"Count:\",len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "assert df.is_blocked.mean() < 0.51\n",
    "assert df.is_blocked.mean() > 0.49\n",
    "assert len(df) <= 560000\n",
    "\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In case your RAM-o-meter is in the red\n",
    "# if very_low_ram:\n",
    "#     data = data[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing\n",
    "\n",
    "First, we create a dictionary of all existing words. Assign each word a number - it's Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter,defaultdict\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "#Dictionary of tokens\n",
    "token_counts = Counter()\n",
    "\n",
    "#All texts\n",
    "all_texts = np.hstack([df.description.values,df.title.values])\n",
    "\n",
    "\n",
    "#Compute token frequencies\n",
    "for s in all_texts:\n",
    "    if type(s) is not str:\n",
    "        continue\n",
    "    s = s.lower()\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    for token in tokens:\n",
    "        token_counts[token] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532495\n"
     ]
    }
   ],
   "source": [
    "print(len(list(token_counts.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare tokens\n",
    "\n",
    "We are unlikely to make use of words that are only seen a few times throughout the corpora.\n",
    "\n",
    "Again, if you want to beat Kaggle competition metrics, consider doing something better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEptJREFUeJzt3V+sndV95vHvMzjDoCYwBlyLGk9NhOfCoKkjLAcpuaBF\nY3uSqlAJMo40xRcIKkGrREo1gtzQElkCaRpapAaJFgvDpAGLJIM1gUEORMr0gj+HlNbYBHFUQNhy\nsIs9kF5AZfKbi71Oun167LM4fzn7fD/Sq/3u3/uutdcSwo/fd717O1WFJEk9/s1iD0CStHQYGpKk\nboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuq1Y7AHMtQsvvLDWrVu32MOQpCXlxRdf\n/MeqWjXdeSMXGuvWrWNsbGyxhyFJS0qSN3vO8/aUJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepm\naEiSuhkakqRuhoYkqdvIfSN8vqy77QdT1t+464sLPBJJWjxeaUiSuhkakqRuhoYkqZuhIUnqZmhI\nkrpNGxpJ1ib5UZKDSQ4k+Uqr/3GSw0leatsXhtrcnmQ8yatJtg7Vr0iyvx27N0la/ewkj7b6c0nW\nDbXZkeS1tu2Yy8lLkj6ankduTwJfq6qfJPkU8GKSfe3YPVX1P4ZPTrIB2A5cBvwa8MMk/7GqPgTu\nA24CngOeALYBTwI3Aieq6tIk24G7gf+a5HzgDmATUO2z91bVidlNW5I0E9NeaVTVkar6Sdv/OfAK\nsOYMTa4BHqmqD6rqdWAc2JzkIuDcqnq2qgp4CLh2qM3utv8YcHW7CtkK7Kuq4y0o9jEIGknSIvhI\naxrtttFnGFwpAPxhkr9PsivJylZbA7w11OxQq61p+5Prp7SpqpPAu8AFZ+hLkrQIukMjySeB7wJf\nrar3GNxq+jSwETgC/Om8jLBvbDcnGUsyduzYscUahiSNvK7QSPIJBoHx7ar6HkBVvV1VH1bVL4C/\nBDa30w8Da4eaX9xqh9v+5PopbZKsAM4D3jlDX6eoqvuralNVbVq1alXPlCRJM9Dz9FSAB4BXquqb\nQ/WLhk77XeDltr8X2N6eiLoEWA88X1VHgPeSXNn6vAF4fKjNxJNR1wHPtHWPp4AtSVa2219bWk2S\ntAh6np76HPB7wP4kL7Xa14EvJ9nI4KmmN4DfB6iqA0n2AAcZPHl1a3tyCuAW4EHgHAZPTT3Z6g8A\nDycZB44zePqKqjqe5BvAC+28O6vq+MymKkmarWlDo6r+BsgUh544Q5udwM4p6mPA5VPU3weuP01f\nu4Bd041TkjT//Ea4JKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnq\nZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnq\nZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuk0bGknWJvlRkoNJDiT5\nSqufn2Rfktfa68qhNrcnGU/yapKtQ/Urkuxvx+5NklY/O8mjrf5cknVDbXa0z3gtyY65nLwk6aPp\nudI4CXytqjYAVwK3JtkA3AY8XVXrgafbe9qx7cBlwDbgW0nOan3dB9wErG/btla/EThRVZcC9wB3\nt77OB+4APgtsBu4YDidJ0sKaNjSq6khV/aTt/xx4BVgDXAPsbqftBq5t+9cAj1TVB1X1OjAObE5y\nEXBuVT1bVQU8NKnNRF+PAVe3q5CtwL6qOl5VJ4B9/EvQSJIW2Eda02i3jT4DPAesrqoj7dDPgNVt\nfw3w1lCzQ622pu1Prp/SpqpOAu8CF5yhr8njujnJWJKxY8eOfZQpSZI+gu7QSPJJ4LvAV6vqveFj\n7cqh5nhs3arq/qraVFWbVq1atVjDkKSR1xUaST7BIDC+XVXfa+W32y0n2uvRVj8MrB1qfnGrHW77\nk+untEmyAjgPeOcMfUmSFkHP01MBHgBeqapvDh3aC0w8zbQDeHyovr09EXUJgwXv59utrPeSXNn6\nvGFSm4m+rgOeaVcvTwFbkqxsC+BbWk2StAhWdJzzOeD3gP1JXmq1rwN3AXuS3Ai8CXwJoKoOJNkD\nHGTw5NWtVfVha3cL8CBwDvBk22AQSg8nGQeOM3j6iqo6nuQbwAvtvDur6vgM5ypJmqVpQ6Oq/gbI\naQ5ffZo2O4GdU9THgMunqL8PXH+avnYBu6YbpyRp/vmNcElSN0NDktTN0JAkdTM0JEndDA1JUjdD\nQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdD\nQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdD\nQ5LUbdrQSLIrydEkLw/V/jjJ4SQvte0LQ8duTzKe5NUkW4fqVyTZ347dmyStfnaSR1v9uSTrhtrs\nSPJa23bM1aQlSTPTc6XxILBtivo9VbWxbU8AJNkAbAcua22+leSsdv59wE3A+rZN9HkjcKKqLgXu\nAe5ufZ0P3AF8FtgM3JFk5UeeoSRpzkwbGlX1Y+B4Z3/XAI9U1QdV9TowDmxOchFwblU9W1UFPARc\nO9Rmd9t/DLi6XYVsBfZV1fGqOgHsY+rwkiQtkNmsafxhkr9vt68mrgDWAG8NnXOo1da0/cn1U9pU\n1UngXeCCM/QlSVokMw2N+4BPAxuBI8CfztmIZiDJzUnGkowdO3ZsMYciSSNtRqFRVW9X1YdV9Qvg\nLxmsOQAcBtYOnXpxqx1u+5Prp7RJsgI4D3jnDH1NNZ77q2pTVW1atWrVTKYkSeowo9BoaxQTfheY\neLJqL7C9PRF1CYMF7+er6gjwXpIr23rFDcDjQ20mnoy6DnimrXs8BWxJsrLd/trSapKkRbJiuhOS\nfAe4CrgwySEGTzRdlWQjUMAbwO8DVNWBJHuAg8BJ4Naq+rB1dQuDJ7HOAZ5sG8ADwMNJxhksuG9v\nfR1P8g3ghXbenVXVuyAvSZoH04ZGVX15ivIDZzh/J7BzivoYcPkU9feB60/T1y5g13RjlCQtDL8R\nLknqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuh\nIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuh\nIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6TRsaSXYlOZrk5aHa+Un2JXmtva4cOnZ7kvEkrybZ\nOlS/Isn+duzeJGn1s5M82urPJVk31GZH+4zXkuyYq0lLkmam50rjQWDbpNptwNNVtR54ur0nyQZg\nO3BZa/OtJGe1NvcBNwHr2zbR543Aiaq6FLgHuLv1dT5wB/BZYDNwx3A4SZIW3rShUVU/Bo5PKl8D\n7G77u4Frh+qPVNUHVfU6MA5sTnIRcG5VPVtVBTw0qc1EX48BV7erkK3Avqo6XlUngH386/CSJC2g\nma5prK6qI23/Z8Dqtr8GeGvovEOttqbtT66f0qaqTgLvAhecoS9J0iKZ9UJ4u3KoORjLjCW5OclY\nkrFjx44t5lAkaaTNNDTebrecaK9HW/0wsHbovItb7XDbn1w/pU2SFcB5wDtn6Otfqar7q2pTVW1a\ntWrVDKckSZrOTENjLzDxNNMO4PGh+vb2RNQlDBa8n2+3st5LcmVbr7hhUpuJvq4DnmlXL08BW5Ks\nbAvgW1pNkrRIVkx3QpLvAFcBFyY5xOCJpruAPUluBN4EvgRQVQeS7AEOAieBW6vqw9bVLQyexDoH\neLJtAA8ADycZZ7Dgvr31dTzJN4AX2nl3VtXkBXlJ0gKaNjSq6sunOXT1ac7fCeycoj4GXD5F/X3g\n+tP0tQvYNd0YJUkLw2+ES5K6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZ\nGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSeo27T/CpDNbd9sPpqy/cdcXF3gkkjT/vNKQ\nJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQ\nJHUzNCRJ3WYVGkneSLI/yUtJxlrt/CT7krzWXlcOnX97kvEkrybZOlS/ovUznuTeJGn1s5M82urP\nJVk3m/FKkmZnLq40frOqNlbVpvb+NuDpqloPPN3ek2QDsB24DNgGfCvJWa3NfcBNwPq2bWv1G4ET\nVXUpcA9w9xyMV5I0Q/Nxe+oaYHfb3w1cO1R/pKo+qKrXgXFgc5KLgHOr6tmqKuChSW0m+noMuHri\nKkSStPBmGxoF/DDJi0lubrXVVXWk7f8MWN321wBvDbU91Gpr2v7k+iltquok8C5wweRBJLk5yViS\nsWPHjs1ySpKk05ntP/f6+ao6nORXgX1Jfjp8sKoqSc3yM6ZVVfcD9wNs2rRp3j9PkparWV1pVNXh\n9noU+D6wGXi73XKivR5tpx8G1g41v7jVDrf9yfVT2iRZAZwHvDObMUuSZm7GoZHkV5J8amIf2AK8\nDOwFdrTTdgCPt/29wPb2RNQlDBa8n2+3st5LcmVbr7hhUpuJvq4DnmnrHpKkRTCb21Orge+3dekV\nwF9X1f9J8gKwJ8mNwJvAlwCq6kCSPcBB4CRwa1V92Pq6BXgQOAd4sm0ADwAPJxkHjjN4+kqStEhm\nHBpV9Q/Ab0xRfwe4+jRtdgI7p6iPAZdPUX8fuH6mY5QkzS2/ES5J6mZoSJK6GRqSpG6GhiSpm6Eh\nSepmaEiSus32Z0R0Gutu+8GU9Tfu+uICj0SS5o5XGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSp\nm6EhSepmaEiSuhkakqRuhoYkqZs/I7LA/HkRSUuZVxqSpG6GhiSpm6EhSepmaEiSurkQ/jHhArmk\npcArDUlSN0NDktTN21Mfc962kvRx4pWGJKmbVxpLlFcgkhaDoTFiDBNJ88nQWCZOFyZgoEjqtyRC\nI8k24M+Bs4C/qqq7FnlII+VMgTIVQ0Zavj72oZHkLOAvgP8MHAJeSLK3qg4u7siWr48aMqdj+EhL\nz8c+NIDNwHhV/QNAkkeAawBDY4mbq/BZCAacNLAUQmMN8NbQ+0PAZxdpLFqmllLAaflaiL/cLIXQ\nmFaSm4Gb29t/SvLqLLq7EPjH2Y9qSVluc15u8wXnvCzk7lnN+dd7TloKoXEYWDv0/uJW+6Wquh+4\nfy4+LMlYVW2ai76WiuU25+U2X3DOy8VCzHkpfCP8BWB9kkuS/FtgO7B3kcckScvSx/5Ko6pOJvkD\n4CkGj9zuqqoDizwsSVqWPvahAVBVTwBPLNDHzcltriVmuc15uc0XnPNyMe9zTlXN92dIkkbEUljT\nkCR9TBgaTZJtSV5NMp7ktsUez3xIsivJ0SQvD9XOT7IvyWvtdeVijnGuJVmb5EdJDiY5kOQrrT6y\n807y75I8n+Tv2pz/pNVHds4w+PWIJH+b5H+396M+3zeS7E/yUpKxVpv3ORsanPJTJf8F2AB8OcmG\nxR3VvHgQ2DapdhvwdFWtB55u70fJSeBrVbUBuBK4tf23HeV5fwD8VlX9BrAR2JbkSkZ7zgBfAV4Z\nej/q8wX4zaraOPSY7bzP2dAY+OVPlVTVPwMTP1UyUqrqx8DxSeVrgN1tfzdw7YIOap5V1ZGq+knb\n/zmDP1TWMMLzroF/am8/0bZihOec5GLgi8BfDZVHdr5nMO9zNjQGpvqpkjWLNJaFtrqqjrT9nwGr\nF3Mw8ynJOuAzwHOM+LzbrZqXgKPAvqoa9Tn/GfDfgV8M1UZ5vjD4i8APk7zYfhUDFmDOS+KRWy2M\nqqokI/k4XZJPAt8FvlpV7yX55bFRnHdVfQhsTPLvge8nuXzS8ZGZc5LfBo5W1YtJrprqnFGa75DP\nV9XhJL8K7Evy0+GD8zVnrzQGpv2pkhH2dpKLANrr0UUez5xL8gkGgfHtqvpeK4/8vAGq6v8BP2Kw\nljWqc/4c8DtJ3mBwa/m3kvxPRne+AFTV4fZ6FPg+g9vs8z5nQ2NgOf9UyV5gR9vfATy+iGOZcxlc\nUjwAvFJV3xw6NLLzTrKqXWGQ5BwG/xbNTxnROVfV7VV1cVWtY/D/7jNV9d8Y0fkCJPmVJJ+a2Ae2\nAC+zAHP2y31Nki8wuC868VMlOxd5SHMuyXeAqxj8+ufbwB3A/wL2AP8BeBP4UlVNXixfspJ8Hvi/\nwH7+5X731xmsa4zkvJP8JwaLoGcx+Ivhnqq6M8kFjOicJ7TbU39UVb89yvNN8mkGVxcwWGb466ra\nuRBzNjQkSd28PSVJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqdv/B0pWyf424tHU\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a0df73400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Word frequency distribution, just for kicks\n",
    "_ = plt.hist(list(token_counts.values()),range=[0,50],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85409\n"
     ]
    }
   ],
   "source": [
    "#Select only the tokens that had at least 10 occurences in the corpora.\n",
    "#Use token_counts.\n",
    "\n",
    "min_count = 10\n",
    "# tokens = <tokens from token_counts keys that had at least min_count occurences throughout the dataset>\n",
    "tokens = [token for token in token_counts.keys() if token_counts[token] > min_count]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {t: i+1 for i,t in enumerate(tokens)}\n",
    "null_token = \"NULL\"\n",
    "token_to_id[null_token] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tokens: 85410\n"
     ]
    }
   ],
   "source": [
    "print(\"# Tokens:\",len(token_to_id))\n",
    "if len(token_to_id) < 30000:\n",
    "    print(\"Alarm! It seems like there are too few tokens. Make sure you updated NLTK and applied correct thresholds -- unless you now what you're doing, ofc\")\n",
    "if len(token_to_id) > 1000000:\n",
    "    print(\"Alarm! Too many tokens. You might have messed up when pruning rare ones -- unless you know what you're doin' ofc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace words with IDs\n",
    "\n",
    "Set a maximum length for titles and descriptions.\n",
    "\n",
    "* If string is longer that that limit - crop it, if less - pad with zeros.\n",
    "* Thus we obtain a matrix of size [n_samples]x[max_length]\n",
    "* Element at i,j - is an identifier of word j within sample i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(strings, token_to_id, max_len=150):\n",
    "    token_matrix = []\n",
    "    for s in strings:\n",
    "        if type(s) is not str:\n",
    "            token_matrix.append([0]*max_len)\n",
    "            continue\n",
    "        # For Python 2.x\n",
    "        # s = s.decode('utf8').lower()\n",
    "        s = s.lower()\n",
    "        tokens = tokenizer.tokenize(s)\n",
    "        token_ids = list(map(lambda token: token_to_id.get(token,0), tokens))[:max_len]\n",
    "        token_ids += [0]*(max_len - len(token_ids))\n",
    "        token_matrix.append(token_ids)\n",
    "\n",
    "    return np.array(token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_tokens = vectorize(df.description.values,token_to_id,max_len = 150)\n",
    "title_tokens = vectorize(df.title.values,token_to_id,max_len = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data format examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (546041, 15)\n",
      "Mazda 6, 2008 -> [4049   49 2438    0    0    0    0    0    0    0] ...\n",
      "Логан стартер -> [7922 2382    0    0    0    0    0    0    0    0] ...\n",
      "Volkswagen Passat, 2007 -> [3304 4758   69    0    0    0    0    0    0    0] ...\n",
      "Crescent 550 wa -> [    0  6163 47703     0     0     0     0     0     0     0] ...\n",
      "Audi Allroad, 2007 -> [  65 4554   69    0    0    0    0    0    0    0] ...\n",
      "Honda Accord, 2008 -> [3814 3981 2438    0    0    0    0    0    0    0] ...\n",
      "Главный тормозной цилиндр на деу матиз -> [5894 1944 2669   26 6598 3430    0    0    0    0] ...\n",
      "Зимние шины всборе с дисками -> [2694 1152 3282   76 1567    0    0    0    0    0] ...\n",
      "Renault Sandero, 2010 -> [4731 2600 3549    0    0    0    0    0    0    0] ...\n",
      "Volkswagen Polo, 2010 -> [3304 4189 3549    0    0    0    0    0    0    0] ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы:\",title_tokens.shape)\n",
    "for title, tokens in zip(df.title.values[:10],title_tokens[:10]):\n",
    "    print(title,'->', tokens[:10],'...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, our preprocessing is somewhat crude. Let us see if that is enough for our network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Non-sequences\n",
    "\n",
    "Some data features are not text samples. E.g. price, # urls, category, etc\n",
    "They require a separate preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All numeric features\n",
    "df_numerical_features = df[[\"phones_cnt\",\"emails_cnt\",\"urls_cnt\",\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One-hot-encoded category and subcategory\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categories = []\n",
    "data_cat_subcat = df[[\"category\",\"subcategory\"]].values\n",
    "\n",
    "# categories = [A list of dictionaries {\"category\":category_name, \"subcategory\":subcategory_name} for each data sample]\n",
    "categories = [{\"category\":cat_name, \"subcategory\":subcat_name} for cat_name, subcat_name in data_cat_subcat]\n",
    "\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "cat_one_hot = vectorizer.fit_transform(categories)\n",
    "cat_one_hot = pd.DataFrame(cat_one_hot,columns=vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_non_text = pd.merge(\n",
    "    df_numerical_features,cat_one_hot,on = np.arange(len(cat_one_hot))\n",
    ")\n",
    "del df_non_text[\"key_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Target variable - whether or not sample contains prohibited material\n",
    "target = df.is_blocked.values.astype('int32')\n",
    "#Preprocessed titles\n",
    "title_tokens = title_tokens.astype('int32')\n",
    "#Preprocessed tokens\n",
    "desc_tokens = desc_tokens.astype('int32')\n",
    "\n",
    "#Non-sequences\n",
    "df_non_text = df_non_text.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for same sort result passed.\n",
      "Test set contains items with item_ids strictly above that of training set.\n",
      "TRAIN: 137785 135235\n",
      "TEST: 137211 135809\n"
     ]
    }
   ],
   "source": [
    "#Split into training and test set.\n",
    "\n",
    "#Difficulty selector:\n",
    "#Easy: split randomly\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = train_test_split(title_tokens,\n",
    "                                                                                               desc_tokens,\n",
    "                                                                                               df_non_text,\n",
    "                                                                                               target)\n",
    "'''\n",
    "#Medium: select test set items that have item_ids strictly above that of training set\n",
    "middle = len(target) // 2\n",
    "sitemids, stitle_tokens, sdesc_tokens, starget = (list(t) for t in zip(*sorted(zip(list(df.itemid.values), list(title_tokens),\n",
    "                                                                          list(desc_tokens), list(target)), \n",
    "                                                                        key=lambda x: x[0])))\n",
    "df_non_text['itemid'] = df.itemid\n",
    "df_nt = df_non_text.sort_values(by='itemid', kind='quicksort')\n",
    "\n",
    "assert sum(df_nt.itemid.values == sitemids) == len(df_nt)\n",
    "print(\"Test for same sort result passed.\")\n",
    "\n",
    "itemid_tr, itemid_ts = sitemids[:middle], sitemids[middle:]\n",
    "title_tr,title_ts = stitle_tokens[:middle], stitle_tokens[middle:]\n",
    "desc_tr,desc_ts = sdesc_tokens[:middle], sdesc_tokens[middle:]\n",
    "nontext_tr,nontext_ts = df_nt.iloc[:middle], df_nt.iloc[middle:], \n",
    "target_tr,target_ts = starget[:middle], starget[middle:]\n",
    "\n",
    "assert max( itemid_tr) < min(itemid_ts)\n",
    "print('Test set contains items with item_ids strictly above that of training set.')\n",
    "\n",
    "# Checking if such simple split provides us with class-balanced train and test sets\n",
    "print(\"TRAIN:\", sum(target_tr), middle-sum(target_tr))\n",
    "print(\"TEST:\", sum(target_ts), middle-sum(target_ts))     \n",
    "\n",
    "data_tuple = (title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts)\n",
    "#Hard: do whatever you want, but score yourself using kaggle private leaderboard\n",
    "\n",
    "# title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = <define_these_variables>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save preprocessed data [optional]\n",
    "\n",
    "* The next tab can be used to stash all the essential data matrices and get rid of the rest of the data.\n",
    "    * Highly recommended if you have less than 1.5GB RAM left\n",
    "    * To do that, you need to first run it with save_prepared_data=True, then restart the notebook and only run this tab with read_prepared_data=True.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading saved data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "save_prepared_data = False #save\n",
    "read_prepared_data = True #load\n",
    "\n",
    "#but not both at once\n",
    "assert not (save_prepared_data and read_prepared_data)\n",
    "\n",
    "if save_prepared_data:\n",
    "    print(\"Saving preprocessed data (may take up to 3 minutes)\")\n",
    "\n",
    "    import pickle\n",
    "    with open(\"preprocessed_data.pcl\",'wb') as fout:\n",
    "        pickle.dump(data_tuple,fout)\n",
    "    with open(\"token_to_id.pcl\",'wb') as fout:\n",
    "        pickle.dump(token_to_id,fout)\n",
    "\n",
    "    print(\"done\")\n",
    "    \n",
    "elif read_prepared_data:\n",
    "    print(\"Reading saved data...\")\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(\"preprocessed_data.pcl\",'rb') as fin:\n",
    "        data_tuple = pickle.load(fin)\n",
    "    title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple\n",
    "    with open(\"token_to_id.pcl\",'rb') as fin:\n",
    "        token_to_id = pickle.load(fin)\n",
    "        \n",
    "    #Re-importing libraries to allow staring noteboook from here\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "   \n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# post-processing\n",
    "title_tr = np.asarray(title_tr,dtype='int32')\n",
    "title_ts = np.asarray(title_ts,dtype='int32')\n",
    "desc_tr = np.asarray(desc_tr,dtype='int32')\n",
    "desc_ts = np.asarray(desc_ts,dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_list = nontext_tr.columns[:-1]\n",
    "nontext_tr = np.asarray(nontext_tr.as_matrix(columns=column_list), dtype='int32')\n",
    "nontext_ts = np.asarray(nontext_ts.as_matrix(columns=column_list), dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train the monster\n",
    "\n",
    "Since we have several data sources, our neural network may differ from what you used to work with.\n",
    "\n",
    "* Separate input for titles: RNN\n",
    "* Separate input for description: RNN\n",
    "* Separate input for categorical features: обычные полносвязные слои или какие-нибудь трюки\n",
    "\n",
    "These three inputs must be blended somehow - concatenated or added.\n",
    "\n",
    "* Output: a simple binary classification\n",
    "    * 1 sigmoidal with binary_crossentropy\n",
    "    * 2 softmax with categorical_crossentropy - essentially the same as previous one\n",
    "    * 1 neuron without nonlinearity (lambda x: x) + hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import lasagne\n",
    "from theano import tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 inputs and a refere output\n",
    "title_token_ids = T.matrix(\"title_token_ids\",dtype='int32')\n",
    "desc_token_ids = T.matrix(\"desc_token_ids\",dtype='int32')\n",
    "categories = T.matrix(\"categories\",dtype='int32')\n",
    "target_y = T.ivector(\"is_blocked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_inp = lasagne.layers.InputLayer((None,title_tr.shape[1]),input_var=title_token_ids)\n",
    "descr_inp = lasagne.layers.InputLayer((None,desc_tr.shape[1]),input_var=desc_token_ids)\n",
    "cat_inp = lasagne.layers.InputLayer((None,nontext_tr.shape[1]), input_var=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Descriptions\n",
    "\n",
    "# word-wise embedding. We recommend to start from some 64 and improving after you are certain it works.\n",
    "# -> output_size=64\n",
    "num_units_descr = 64\n",
    "out_size = 96\n",
    "descr_nn = lasagne.layers.EmbeddingLayer(descr_inp, input_size=len(token_to_id)+1, output_size = out_size)\n",
    "# descr_nn = RNN or LSTM over embedding, maybe several ones in a stack\n",
    "descr_nn = lasagne.layers.ReshapeLayer(descr_nn, (-1,1,out_size*desc_tr.shape[1]))\n",
    "descr_nn = lasagne.layers.LSTMLayer(descr_nn, num_units_descr)\n",
    "\n",
    "# Titles\n",
    "# title_nn = <Process titles somehow (title_inp)>\n",
    "num_units_titles = 32\n",
    "title_nn = lasagne.layers.ReshapeLayer(title_inp, (-1,1,title_tr.shape[1]))\n",
    "title_nn = lasagne.layers.RecurrentLayer(title_nn, num_units=num_units_titles)\n",
    "# title_nn = lasagne.layers.RecurrentLayer(title_nn, num_units)\n",
    "\n",
    "# Non-sequences\n",
    "# cat_nn = <Process non-sequences(cat_inp)>\n",
    "num_units_cat = 16\n",
    "cat_nn = lasagne.layers.DenseLayer(cat_inp, num_units=num_units_cat, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "cat_nn = lasagne.layers.DenseLayer(cat_nn, num_units=num_units_cat, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "cat_nn = lasagne.layers.ReshapeLayer(cat_nn, (-1,1,num_units_cat))\n",
    "# cat_nn = lasagne.layers.DenseLayer(cat_inp, num_units=num_units, nonlinearity=lasagne.nonlinearities.rectify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 1, 64), (None, 1, 32), (None, 1, 16)]\n"
     ]
    }
   ],
   "source": [
    "# nn = <merge three layers into one (e.g. lasagne.layers.concat) >\n",
    "nn = lasagne.layers.concat([descr_nn, title_nn, cat_nn], axis=2)\n",
    "print(nn.input_shapes)\n",
    "\n",
    "# nn = lasagne.layers.DenseLayer(nn,your_lucky_number)\n",
    "# nn = lasagne.layers.DropoutLayer(nn,p=maybe_use_me)\n",
    "# nn = lasagne.layers.DenseLayer(nn,1,nonlinearity=lasagne.nonlinearities.linear)\n",
    "\n",
    "nn = lasagne.layers.DenseLayer(nn, num_units_descr+num_units_titles+num_units_cat)\n",
    "nn = lasagne.layers.DropoutLayer(nn, p=0.1)\n",
    "nn = lasagne.layers.DenseLayer(nn,1,nonlinearity=lasagne.nonlinearities.linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "* The standard way:\n",
    "    * prediction\n",
    "    * loss\n",
    "    * updates\n",
    "    * training and evaluation functions\n",
    "\n",
    "* Hinge loss\n",
    "    * $ L_i = \\max(0, \\delta - t_i p_i) $\n",
    "    * delta is a tunable parameter: how far should a neuron be in the positive margin area for us to stop bothering about it\n",
    "    * Function description may mention some +-1 limitations - this is not neccessary, at least as long as hinge loss has a default flag binary = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All trainable params\n",
    "weights = lasagne.layers.get_all_params(nn,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simple NN prediction\n",
    "prediction = lasagne.layers.get_output(nn)[:,0]\n",
    "\n",
    "#Hinge loss\n",
    "# loss = lasagne.objectives.binary_hinge_loss(prediction,target_y,delta = what_do_you_think).mean()\n",
    "loss = lasagne.objectives.binary_hinge_loss(prediction,target_y,delta = 1, log_odds=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight optimization step\n",
    "# updates = <your favorite optimizer>\n",
    "updates = lasagne.updates.adagrad(loss, weights, learning_rate=1e-1)\n",
    "# updates = lasagne.updates.nesterov_momentum(loss, weights, learning_rate=1e-4, momentum=.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinitic prediction\n",
    "\n",
    "* In case we use stochastic elements, e.g. dropout or noize\n",
    "* Compile a separate set of functions with deterministic prediction (deterministic = True)\n",
    "* Unless you think there's no neet for dropout there ofc. Btw is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lasagne.objectives import aggregate\n",
    "#deterministic version\n",
    "det_prediction = lasagne.layers.get_output(nn,deterministic=True)[:,0]\n",
    "\n",
    "#equivalent loss function\n",
    "# det_loss = <an excercise in copy-pasting and editing>\n",
    "det_loss = aggregate(lasagne.objectives.binary_hinge_loss(det_prediction,target_y,delta = 1, log_odds=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coffee-lation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efimov/.conda/envs/py3/lib/python3.6/site-packages/theano/tensor/basic.py:5130: UserWarning: flatten outdim parameter is deprecated, use ndim instead.\n",
      "  \"flatten outdim parameter is deprecated, use ndim instead.\")\n"
     ]
    }
   ],
   "source": [
    "train_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[loss,prediction],updates = updates)\n",
    "eval_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[det_loss,det_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "* The regular way with loops over minibatches\n",
    "* Since the dataset is huge, we define epoch as some fixed amount of samples isntead of all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#average precision at K\n",
    "\n",
    "from oracle import APatK, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out good old minibatch iterator now supports arbitrary amount of arrays (X,y,z)\n",
    "\n",
    "def iterate_minibatches(*arrays,**kwargs):\n",
    "    batchsize=kwargs.get(\"batchsize\", 100)\n",
    "    shuffle = kwargs.get(\"shuffle\", True)\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(len(arrays[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(arrays[0]) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            print(start_idx, indices[:10])\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield [arr[excerpt] for arr in arrays]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaking guide\n",
    "\n",
    "* batch_size - how many samples are processed per function call\n",
    "    * optimization gets slower, but more stable, as you increase it.\n",
    "    * May consider increasing it halfway through training\n",
    "* minibatches_per_epoch - max amount of minibatches per epoch\n",
    "    * Does not affect training. Lesser value means more frequent and less stable printing\n",
    "    * Setting it to less than 10 is only meaningfull if you want to make sure your NN does not break down after one epoch\n",
    "* n_epochs - total amount of epochs to train for\n",
    "    * n_epochs = 10**10 and manual interrupting is still an option\n",
    "\n",
    "Tips:\n",
    "\n",
    "* With small minibatches_per_epoch, network quality may jump around 0.5 for several epochs\n",
    "* AUC is the most stable of all three metrics\n",
    "* Average Precision at top 2.5% (APatK) - is the least stable. If batch_size*minibatches_per_epoch < 10k, it behaves as a uniform random variable.\n",
    "* Plotting metrics over training time may be a good way to analyze which architectures work better.\n",
    "* Once you are sure your network aint gonna crash, it's worth letting it train for a few hours of an average laptop's time to see it's true potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH # 0\n",
      "Train:\n",
      "\tloss: 6088.53861834\n",
      "\tacc: 0.556732673267\n",
      "\tauc: 0.572736691465\n",
      "Val:\n",
      "\tloss: 13.1964950978\n",
      "\tacc: 0.500297029703\n",
      "\tauc: 0.504340169431\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 1\n",
      "Train:\n",
      "\tloss: 9.31562230817\n",
      "\tacc: 0.544257425743\n",
      "\tauc: 0.563547114506\n",
      "Val:\n",
      "\tloss: 2.16497890873\n",
      "\tacc: 0.552475247525\n",
      "\tauc: 0.572179482489\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 2\n",
      "Train:\n",
      "\tloss: 2.30847055536\n",
      "\tacc: 0.529207920792\n",
      "\tauc: 0.55488831478\n",
      "Val:\n",
      "\tloss: 2.0778475269\n",
      "\tacc: 0.549108910891\n",
      "\tauc: 0.567515092634\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 3\n",
      "Train:\n",
      "\tloss: 1.37504179016\n",
      "\tacc: 0.548415841584\n",
      "\tauc: 0.579399142725\n",
      "Val:\n",
      "\tloss: 1.26746621464\n",
      "\tacc: 0.570495049505\n",
      "\tauc: 0.603591426882\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 4\n",
      "Train:\n",
      "\tloss: 1.16432703242\n",
      "\tacc: 0.586930693069\n",
      "\tauc: 0.616338014362\n",
      "Val:\n",
      "\tloss: 1.09996515426\n",
      "\tacc: 0.579900990099\n",
      "\tauc: 0.618522378564\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 5\n",
      "Train:\n",
      "\tloss: 1.1121249218\n",
      "\tacc: 0.607821782178\n",
      "\tauc: 0.637213176166\n",
      "Val:\n",
      "\tloss: 0.82469213983\n",
      "\tacc: 0.655346534653\n",
      "\tauc: 0.708174513727\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 6\n",
      "Train:\n",
      "\tloss: 0.967732774638\n",
      "\tacc: 0.602178217822\n",
      "\tauc: 0.633958229813\n",
      "Val:\n",
      "\tloss: 1.09816974139\n",
      "\tacc: 0.564455445545\n",
      "\tauc: 0.575057355068\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 7\n",
      "Train:\n",
      "\tloss: 1.36490390608\n",
      "\tacc: 0.59900990099\n",
      "\tauc: 0.631487760842\n",
      "Val:\n",
      "\tloss: 0.932436940385\n",
      "\tacc: 0.581089108911\n",
      "\tauc: 0.620598695126\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 8\n",
      "Train:\n",
      "\tloss: 0.92906873874\n",
      "\tacc: 0.593762376238\n",
      "\tauc: 0.625230275122\n",
      "Val:\n",
      "\tloss: 0.868588405318\n",
      "\tacc: 0.601089108911\n",
      "\tauc: 0.64560452244\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 9\n",
      "Train:\n",
      "\tloss: 0.921014360344\n",
      "\tacc: 0.597524752475\n",
      "\tauc: 0.630079113673\n",
      "Val:\n",
      "\tloss: 0.887983154025\n",
      "\tacc: 0.603069306931\n",
      "\tauc: 0.644229319696\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 10\n",
      "Train:\n",
      "\tloss: 0.876603527952\n",
      "\tacc: 0.603069306931\n",
      "\tauc: 0.649664119937\n",
      "Val:\n",
      "\tloss: 0.859377893003\n",
      "\tacc: 0.614257425743\n",
      "\tauc: 0.657973006456\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 11\n",
      "Train:\n",
      "\tloss: 0.862955414136\n",
      "\tacc: 0.614851485149\n",
      "\tauc: 0.655630029538\n",
      "Val:\n",
      "\tloss: 0.863091921768\n",
      "\tacc: 0.605544554455\n",
      "\tauc: 0.653739804561\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 12\n",
      "Train:\n",
      "\tloss: 0.872906988271\n",
      "\tacc: 0.613267326733\n",
      "\tauc: 0.655948724929\n",
      "Val:\n",
      "\tloss: 0.802168028932\n",
      "\tacc: 0.63603960396\n",
      "\tauc: 0.690983057276\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 13\n",
      "Train:\n",
      "\tloss: 0.743811962734\n",
      "\tacc: 0.675445544554\n",
      "\tauc: 0.748072282193\n",
      "Val:\n",
      "\tloss: 0.638959365129\n",
      "\tacc: 0.714059405941\n",
      "\tauc: 0.807904083708\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 14\n",
      "Train:\n",
      "\tloss: 0.607936212958\n",
      "\tacc: 0.738316831683\n",
      "\tauc: 0.824966681423\n",
      "Val:\n",
      "\tloss: 0.593252727618\n",
      "\tacc: 0.739108910891\n",
      "\tauc: 0.832630591432\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 15\n",
      "Train:\n",
      "\tloss: 0.582168280457\n",
      "\tacc: 0.743861386139\n",
      "\tauc: 0.838291677492\n",
      "Val:\n",
      "\tloss: 0.556473696716\n",
      "\tacc: 0.762871287129\n",
      "\tauc: 0.848084274173\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 16\n",
      "Train:\n",
      "\tloss: 0.551552378963\n",
      "\tacc: 0.768118811881\n",
      "\tauc: 0.861267125233\n",
      "Val:\n",
      "\tloss: 0.511238744131\n",
      "\tacc: 0.783465346535\n",
      "\tauc: 0.872169351957\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 17\n",
      "Train:\n",
      "\tloss: 0.482430789671\n",
      "\tacc: 0.784851485149\n",
      "\tauc: 0.883807373615\n",
      "Val:\n",
      "\tloss: 0.50101021164\n",
      "\tacc: 0.785544554455\n",
      "\tauc: 0.87926912719\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 18\n",
      "Train:\n",
      "\tloss: 0.456504989777\n",
      "\tacc: 0.800099009901\n",
      "\tauc: 0.894099026979\n",
      "Val:\n",
      "\tloss: 0.425520040357\n",
      "\tacc: 0.821881188119\n",
      "\tauc: 0.911341207524\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 19\n",
      "Train:\n",
      "\tloss: 0.604958753103\n",
      "\tacc: 0.827128712871\n",
      "\tauc: 0.9093608159\n",
      "Val:\n",
      "\tloss: 0.420790028483\n",
      "\tacc: 0.828514851485\n",
      "\tauc: 0.914323960233\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 20\n",
      "Train:\n",
      "\tloss: 0.394248832623\n",
      "\tacc: 0.832673267327\n",
      "\tauc: 0.917288348839\n",
      "Val:\n",
      "\tloss: 0.454071754601\n",
      "\tacc: 0.821089108911\n",
      "\tauc: 0.910864346056\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 21\n",
      "Train:\n",
      "\tloss: 0.368811419692\n",
      "\tacc: 0.851188118812\n",
      "\tauc: 0.923683246741\n",
      "Val:\n",
      "\tloss: 0.352738248766\n",
      "\tacc: 0.850891089109\n",
      "\tauc: 0.931226269163\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 22\n",
      "Train:\n",
      "\tloss: 0.353638300484\n",
      "\tacc: 0.856831683168\n",
      "\tauc: 0.930578864267\n",
      "Val:\n",
      "\tloss: 0.360107959829\n",
      "\tacc: 0.85702970297\n",
      "\tauc: 0.935565199281\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 23\n",
      "Train:\n",
      "\tloss: 0.343046383966\n",
      "\tacc: 0.85603960396\n",
      "\tauc: 0.93308870496\n",
      "Val:\n",
      "\tloss: 0.368299560787\n",
      "\tacc: 0.85\n",
      "\tauc: 0.92998146113\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 24\n",
      "Train:\n",
      "\tloss: 0.337995249809\n",
      "\tacc: 0.860693069307\n",
      "\tauc: 0.935645043155\n",
      "Val:\n",
      "\tloss: 0.327242898163\n",
      "\tacc: 0.864851485149\n",
      "\tauc: 0.939506950839\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 25\n",
      "Train:\n",
      "\tloss: 0.33539004479\n",
      "\tacc: 0.866930693069\n",
      "\tauc: 0.935376223876\n",
      "Val:\n",
      "\tloss: 0.330668452715\n",
      "\tacc: 0.863861386139\n",
      "\tauc: 0.936293238946\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 26\n",
      "Train:\n",
      "\tloss: 0.317287686668\n",
      "\tacc: 0.867623762376\n",
      "\tauc: 0.940000261197\n",
      "Val:\n",
      "\tloss: 0.319273795182\n",
      "\tacc: 0.867326732673\n",
      "\tauc: 0.939095289505\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 27\n",
      "Train:\n",
      "\tloss: 0.311149548094\n",
      "\tacc: 0.874257425743\n",
      "\tauc: 0.94043304472\n",
      "Val:\n",
      "\tloss: 0.300849214873\n",
      "\tacc: 0.874851485149\n",
      "\tauc: 0.946269362243\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 28\n",
      "Train:\n",
      "\tloss: 0.295880820423\n",
      "\tacc: 0.87900990099\n",
      "\tauc: 0.947657232273\n",
      "Val:\n",
      "\tloss: 0.311598297275\n",
      "\tacc: 0.870792079208\n",
      "\tauc: 0.940611599884\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 29\n",
      "Train:\n",
      "\tloss: 0.285942917435\n",
      "\tacc: 0.88603960396\n",
      "\tauc: 0.948370099799\n",
      "Val:\n",
      "\tloss: 0.316329921353\n",
      "\tacc: 0.865940594059\n",
      "\tauc: 0.939306016447\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 30\n",
      "Train:\n",
      "\tloss: 0.277668401109\n",
      "\tacc: 0.88702970297\n",
      "\tauc: 0.949202397541\n",
      "Val:\n",
      "\tloss: 0.285331494211\n",
      "\tacc: 0.879900990099\n",
      "\tauc: 0.948763119254\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 31\n",
      "Train:\n",
      "\tloss: 0.273904289697\n",
      "\tacc: 0.887623762376\n",
      "\tauc: 0.951428750362\n",
      "Val:\n",
      "\tloss: 0.292637398904\n",
      "\tacc: 0.879207920792\n",
      "\tauc: 0.945141104797\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 32\n",
      "Train:\n",
      "\tloss: 0.271733853413\n",
      "\tacc: 0.888316831683\n",
      "\tauc: 0.952492585391\n",
      "Val:\n",
      "\tloss: 0.279420161007\n",
      "\tacc: 0.886534653465\n",
      "\tauc: 0.949741091684\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 33\n",
      "Train:\n",
      "\tloss: 0.253366527383\n",
      "\tacc: 0.895841584158\n",
      "\tauc: 0.954926999548\n",
      "Val:\n",
      "\tloss: 0.284752639644\n",
      "\tacc: 0.880396039604\n",
      "\tauc: 0.946215995498\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 34\n",
      "Train:\n",
      "\tloss: 0.248030808963\n",
      "\tacc: 0.897623762376\n",
      "\tauc: 0.957544612042\n",
      "Val:\n",
      "\tloss: 0.262392730865\n",
      "\tacc: 0.892475247525\n",
      "\tauc: 0.954709406939\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 35\n",
      "Train:\n",
      "\tloss: 0.243287694521\n",
      "\tacc: 0.900495049505\n",
      "\tauc: 0.957176365426\n",
      "Val:\n",
      "\tloss: 0.250130698507\n",
      "\tacc: 0.897920792079\n",
      "\tauc: 0.957640289957\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 36\n",
      "Train:\n",
      "\tloss: 0.241457935433\n",
      "\tacc: 0.899801980198\n",
      "\tauc: 0.958854663202\n",
      "Val:\n",
      "\tloss: 0.265507288374\n",
      "\tacc: 0.891683168317\n",
      "\tauc: 0.952517745218\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 37\n",
      "Train:\n",
      "\tloss: 0.23698889889\n",
      "\tacc: 0.902673267327\n",
      "\tauc: 0.959338608384\n",
      "Val:\n",
      "\tloss: 0.26211409509\n",
      "\tacc: 0.889801980198\n",
      "\tauc: 0.956636816439\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 38\n",
      "Train:\n",
      "\tloss: 0.222979598729\n",
      "\tacc: 0.905445544554\n",
      "\tauc: 0.961805812094\n",
      "Val:\n",
      "\tloss: 0.239370482231\n",
      "\tacc: 0.898118811881\n",
      "\tauc: 0.960373528967\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 39\n",
      "Train:\n",
      "\tloss: 0.230040277204\n",
      "\tacc: 0.905544554455\n",
      "\tauc: 0.96017870557\n",
      "Val:\n",
      "\tloss: 0.253361148644\n",
      "\tacc: 0.89504950495\n",
      "\tauc: 0.954964515619\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 40\n",
      "Train:\n",
      "\tloss: 0.211188276657\n",
      "\tacc: 0.912871287129\n",
      "\tauc: 0.964391595457\n",
      "Val:\n",
      "\tloss: 0.264392008862\n",
      "\tacc: 0.884356435644\n",
      "\tauc: 0.952956796169\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 41\n",
      "Train:\n",
      "\tloss: 0.227271019361\n",
      "\tacc: 0.911089108911\n",
      "\tauc: 0.962785472284\n",
      "Val:\n",
      "\tloss: 0.24534417014\n",
      "\tacc: 0.901584158416\n",
      "\tauc: 0.957159330048\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 42\n",
      "Train:\n",
      "\tloss: 0.2067045884\n",
      "\tacc: 0.918910891089\n",
      "\tauc: 0.967048411626\n",
      "Val:\n",
      "\tloss: 0.240116608873\n",
      "\tacc: 0.898217821782\n",
      "\tauc: 0.958089517696\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 43\n",
      "Train:\n",
      "\tloss: 0.205687169485\n",
      "\tacc: 0.912871287129\n",
      "\tauc: 0.965480549502\n",
      "Val:\n",
      "\tloss: 0.230117836789\n",
      "\tacc: 0.901287128713\n",
      "\tauc: 0.962207837879\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 44\n",
      "Train:\n",
      "\tloss: 0.202610430952\n",
      "\tacc: 0.915742574257\n",
      "\tauc: 0.966142366562\n",
      "Val:\n",
      "\tloss: 0.227411697748\n",
      "\tacc: 0.90198019802\n",
      "\tauc: 0.960960456898\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 45\n",
      "Train:\n",
      "\tloss: 0.193557754609\n",
      "\tacc: 0.919108910891\n",
      "\tauc: 0.967855557929\n",
      "Val:\n",
      "\tloss: 0.261394057766\n",
      "\tacc: 0.900891089109\n",
      "\tauc: 0.959106457568\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 46\n",
      "Train:\n",
      "\tloss: 0.183724489242\n",
      "\tacc: 0.92495049505\n",
      "\tauc: 0.970450282603\n",
      "Val:\n",
      "\tloss: 0.243571169752\n",
      "\tacc: 0.899108910891\n",
      "\tauc: 0.958478095492\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 47\n",
      "Train:\n",
      "\tloss: 0.186766494471\n",
      "\tacc: 0.922871287129\n",
      "\tauc: 0.971195920597\n",
      "Val:\n",
      "\tloss: 0.254784792197\n",
      "\tacc: 0.909603960396\n",
      "\tauc: 0.965049974052\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 48\n",
      "Train:\n",
      "\tloss: 0.19477018059\n",
      "\tacc: 0.92603960396\n",
      "\tauc: 0.972083329951\n",
      "Val:\n",
      "\tloss: 0.220005232824\n",
      "\tacc: 0.906237623762\n",
      "\tauc: 0.963376447892\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 49\n",
      "Train:\n",
      "\tloss: 0.186552645318\n",
      "\tacc: 0.920693069307\n",
      "\tauc: 0.969725068446\n",
      "Val:\n",
      "\tloss: 0.226225708083\n",
      "\tacc: 0.904455445545\n",
      "\tauc: 0.962065007674\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 50\n",
      "Train:\n",
      "\tloss: 0.182181372196\n",
      "\tacc: 0.924554455446\n",
      "\tauc: 0.971784115466\n",
      "Val:\n",
      "\tloss: 0.242249609343\n",
      "\tacc: 0.902475247525\n",
      "\tauc: 0.960145052422\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 51\n",
      "Train:\n",
      "\tloss: 0.176641318095\n",
      "\tacc: 0.928118811881\n",
      "\tauc: 0.97073688818\n",
      "Val:\n",
      "\tloss: 0.217948538544\n",
      "\tacc: 0.907722772277\n",
      "\tauc: 0.960549118568\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 52\n",
      "Train:\n",
      "\tloss: 0.1710929921\n",
      "\tacc: 0.928712871287\n",
      "\tauc: 0.972157292929\n",
      "Val:\n",
      "\tloss: 0.24010291576\n",
      "\tacc: 0.898217821782\n",
      "\tauc: 0.956392223936\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 53\n",
      "Train:\n",
      "\tloss: 0.173432018299\n",
      "\tacc: 0.927425742574\n",
      "\tauc: 0.972523654969\n",
      "Val:\n",
      "\tloss: 0.218028736918\n",
      "\tacc: 0.908118811881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tauc: 0.961883441305\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 54\n",
      "Train:\n",
      "\tloss: 23.6691219841\n",
      "\tacc: 0.890198019802\n",
      "\tauc: 0.925259568136\n",
      "Val:\n",
      "\tloss: 0.256356775025\n",
      "\tacc: 0.89702970297\n",
      "\tauc: 0.949557216194\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 55\n",
      "Train:\n",
      "\tloss: 0.214462301665\n",
      "\tacc: 0.914851485149\n",
      "\tauc: 0.960299969117\n",
      "Val:\n",
      "\tloss: 0.260500572441\n",
      "\tacc: 0.89396039604\n",
      "\tauc: 0.948445050582\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 56\n",
      "Train:\n",
      "\tloss: 0.197109105844\n",
      "\tacc: 0.921584158416\n",
      "\tauc: 0.963190188861\n",
      "Val:\n",
      "\tloss: 0.254887153411\n",
      "\tacc: 0.891584158416\n",
      "\tauc: 0.95081169858\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 57\n",
      "Train:\n",
      "\tloss: 0.186889264676\n",
      "\tacc: 0.92495049505\n",
      "\tauc: 0.964824699447\n",
      "Val:\n",
      "\tloss: 0.230835738687\n",
      "\tacc: 0.905247524752\n",
      "\tauc: 0.953505834512\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 58\n",
      "Train:\n",
      "\tloss: 0.185564344258\n",
      "\tacc: 0.925643564356\n",
      "\tauc: 0.966177511349\n",
      "Val:\n",
      "\tloss: 0.225953063928\n",
      "\tacc: 0.91\n",
      "\tauc: 0.959573403942\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 59\n",
      "Train:\n",
      "\tloss: 0.1861360807\n",
      "\tacc: 0.923861386139\n",
      "\tauc: 0.96687693487\n",
      "Val:\n",
      "\tloss: 0.219803451298\n",
      "\tacc: 0.910495049505\n",
      "\tauc: 0.96154641913\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 60\n",
      "Train:\n",
      "\tloss: 0.184703470898\n",
      "\tacc: 0.92495049505\n",
      "\tauc: 0.967073611739\n",
      "Val:\n",
      "\tloss: 0.227908862872\n",
      "\tacc: 0.90495049505\n",
      "\tauc: 0.956808929461\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 61\n",
      "Train:\n",
      "\tloss: 0.177779181266\n",
      "\tacc: 0.928217821782\n",
      "\tauc: 0.969412539486\n",
      "Val:\n",
      "\tloss: 0.225756132214\n",
      "\tacc: 0.907425742574\n",
      "\tauc: 0.959348567293\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 62\n",
      "Train:\n",
      "\tloss: 0.176316352295\n",
      "\tacc: 0.930693069307\n",
      "\tauc: 0.968084047766\n",
      "Val:\n",
      "\tloss: 0.223531173411\n",
      "\tacc: 0.906435643564\n",
      "\tauc: 0.954093463368\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 63\n",
      "Train:\n",
      "\tloss: 0.165543054855\n",
      "\tacc: 0.930891089109\n",
      "\tauc: 0.968995302597\n",
      "Val:\n",
      "\tloss: 0.229084951047\n",
      "\tacc: 0.908316831683\n",
      "\tauc: 0.957181648491\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 64\n",
      "Train:\n",
      "\tloss: 0.157149950326\n",
      "\tacc: 0.935643564356\n",
      "\tauc: 0.972950796627\n",
      "Val:\n",
      "\tloss: 0.221236463383\n",
      "\tacc: 0.907128712871\n",
      "\tauc: 0.960374490211\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 65\n",
      "Train:\n",
      "\tloss: 0.162194142115\n",
      "\tacc: 0.93495049505\n",
      "\tauc: 0.96894680797\n",
      "Val:\n",
      "\tloss: 0.213049700814\n",
      "\tacc: 0.914059405941\n",
      "\tauc: 0.959746872785\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 66\n",
      "Train:\n",
      "\tloss: 0.153036432917\n",
      "\tacc: 0.937722772277\n",
      "\tauc: 0.971654298982\n",
      "Val:\n",
      "\tloss: 0.202966146001\n",
      "\tacc: 0.915544554455\n",
      "\tauc: 0.959071814805\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 67\n",
      "Train:\n",
      "\tloss: 0.162842540277\n",
      "\tacc: 0.934257425743\n",
      "\tauc: 0.970875450503\n",
      "Val:\n",
      "\tloss: 0.230067496281\n",
      "\tacc: 0.911386138614\n",
      "\tauc: 0.960383815918\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 68\n",
      "Train:\n",
      "\tloss: 0.149571435036\n",
      "\tacc: 0.94\n",
      "\tauc: 0.972081155443\n",
      "Val:\n",
      "\tloss: 0.211858342648\n",
      "\tacc: 0.917722772277\n",
      "\tauc: 0.961874586042\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 69\n",
      "Train:\n",
      "\tloss: 0.142829328181\n",
      "\tacc: 0.943861386139\n",
      "\tauc: 0.97416457132\n",
      "Val:\n",
      "\tloss: 0.212254174821\n",
      "\tacc: 0.913465346535\n",
      "\tauc: 0.95876958228\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 70\n",
      "Train:\n",
      "\tloss: 0.143410677991\n",
      "\tacc: 0.940891089109\n",
      "\tauc: 0.973555736722\n",
      "Val:\n",
      "\tloss: 0.215568249575\n",
      "\tacc: 0.915742574257\n",
      "\tauc: 0.956950818345\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 71\n",
      "Train:\n",
      "\tloss: 0.156243822141\n",
      "\tacc: 0.934752475248\n",
      "\tauc: 0.969822826037\n",
      "Val:\n",
      "\tloss: 0.204457678959\n",
      "\tacc: 0.91396039604\n",
      "\tauc: 0.957629843364\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 72\n",
      "Train:\n",
      "\tloss: 0.140652365954\n",
      "\tacc: 0.942574257426\n",
      "\tauc: 0.9737003442\n",
      "Val:\n",
      "\tloss: 0.214259782373\n",
      "\tacc: 0.917326732673\n",
      "\tauc: 0.959120713656\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 73\n",
      "Train:\n",
      "\tloss: 0.134755951131\n",
      "\tacc: 0.944257425743\n",
      "\tauc: 0.974751879955\n",
      "Val:\n",
      "\tloss: 0.234017644798\n",
      "\tacc: 0.913069306931\n",
      "\tauc: 0.960839654869\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 74\n",
      "Train:\n",
      "\tloss: 0.134045768081\n",
      "\tacc: 0.945445544554\n",
      "\tauc: 0.976509611162\n",
      "Val:\n",
      "\tloss: 0.195058514771\n",
      "\tacc: 0.921683168317\n",
      "\tauc: 0.962328479883\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 75\n",
      "Train:\n",
      "\tloss: 0.125055375798\n",
      "\tacc: 0.949207920792\n",
      "\tauc: 0.977547458356\n",
      "Val:\n",
      "\tloss: 0.208715173649\n",
      "\tacc: 0.916930693069\n",
      "\tauc: 0.956480043435\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 76\n",
      "Train:\n",
      "\tloss: 0.141596894825\n",
      "\tacc: 0.939801980198\n",
      "\tauc: 0.974475094269\n",
      "Val:\n",
      "\tloss: 0.191370535071\n",
      "\tacc: 0.92\n",
      "\tauc: 0.963388927398\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 77\n",
      "Train:\n",
      "\tloss: 0.121420437974\n",
      "\tacc: 0.948613861386\n",
      "\tauc: 0.978499104097\n",
      "Val:\n",
      "\tloss: 0.194097692839\n",
      "\tacc: 0.921386138614\n",
      "\tauc: 0.962942916865\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 78\n",
      "Train:\n",
      "\tloss: 0.123085745992\n",
      "\tacc: 0.952178217822\n",
      "\tauc: 0.979300244262\n",
      "Val:\n",
      "\tloss: 0.204654214084\n",
      "\tacc: 0.918514851485\n",
      "\tauc: 0.960576581063\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 79\n",
      "Train:\n",
      "\tloss: 0.133399671262\n",
      "\tacc: 0.945742574257\n",
      "\tauc: 0.978590799717\n",
      "Val:\n",
      "\tloss: 0.195385761435\n",
      "\tacc: 0.918712871287\n",
      "\tauc: 0.962635927426\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 80\n",
      "Train:\n",
      "\tloss: 0.121060621066\n",
      "\tacc: 0.950594059406\n",
      "\tauc: 0.979255318398\n",
      "Val:\n",
      "\tloss: 0.204646883757\n",
      "\tacc: 0.919702970297\n",
      "\tauc: 0.959899913883\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 81\n",
      "Train:\n",
      "\tloss: 0.117994299857\n",
      "\tacc: 0.952178217822\n",
      "\tauc: 0.977833354085\n",
      "Val:\n",
      "\tloss: 0.205201711225\n",
      "\tacc: 0.91900990099\n",
      "\tauc: 0.961562088274\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 82\n",
      "Train:\n",
      "\tloss: 0.119928331666\n",
      "\tacc: 0.950495049505\n",
      "\tauc: 0.977951944512\n",
      "Val:\n",
      "\tloss: 0.209640025366\n",
      "\tacc: 0.91396039604\n",
      "\tauc: 0.956222549485\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 83\n",
      "Train:\n",
      "\tloss: 0.117115838563\n",
      "\tacc: 0.950891089109\n",
      "\tauc: 0.980677718838\n",
      "Val:\n",
      "\tloss: 0.200987262676\n",
      "\tacc: 0.918514851485\n",
      "\tauc: 0.959078054473\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 84\n",
      "Train:\n",
      "\tloss: 0.124089230349\n",
      "\tacc: 0.948415841584\n",
      "\tauc: 0.97865026974\n",
      "Val:\n",
      "\tloss: 0.195694199713\n",
      "\tacc: 0.922574257426\n",
      "\tauc: 0.964370183562\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 85\n",
      "Train:\n",
      "\tloss: 0.12131240458\n",
      "\tacc: 0.948613861386\n",
      "\tauc: 0.977540627451\n",
      "Val:\n",
      "\tloss: 0.19942400257\n",
      "\tacc: 0.916831683168\n",
      "\tauc: 0.960960742998\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 86\n",
      "Train:\n",
      "\tloss: 0.108656113952\n",
      "\tacc: 0.95504950495\n",
      "\tauc: 0.980892850084\n",
      "Val:\n",
      "\tloss: 0.20647893809\n",
      "\tacc: 0.915742574257\n",
      "\tauc: 0.955290759973\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 87\n",
      "Train:\n",
      "\tloss: 0.119295975642\n",
      "\tacc: 0.951386138614\n",
      "\tauc: 0.977115174235\n",
      "Val:\n",
      "\tloss: 0.208968718257\n",
      "\tacc: 0.910594059406\n",
      "\tauc: 0.952190669504\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 88\n",
      "Train:\n",
      "\tloss: 0.116064588048\n",
      "\tacc: 0.952871287129\n",
      "\tauc: 0.97942696484\n",
      "Val:\n",
      "\tloss: 0.205090993664\n",
      "\tacc: 0.91603960396\n",
      "\tauc: 0.960114750037\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 89\n",
      "Train:\n",
      "\tloss: 0.117952798923\n",
      "\tacc: 0.952772277228\n",
      "\tauc: 0.979100472783\n",
      "Val:\n",
      "\tloss: 0.194833786016\n",
      "\tacc: 0.922376237624\n",
      "\tauc: 0.965483124923\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 90\n",
      "Train:\n",
      "\tloss: 0.110770611618\n",
      "\tacc: 0.95198019802\n",
      "\tauc: 0.97995806861\n",
      "Val:\n",
      "\tloss: 0.199801269002\n",
      "\tacc: 0.923168316832\n",
      "\tauc: 0.962316213385\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 91\n",
      "Train:\n",
      "\tloss: 0.113813051093\n",
      "\tacc: 0.954752475248\n",
      "\tauc: 0.979086125442\n",
      "Val:\n",
      "\tloss: 0.197188991678\n",
      "\tacc: 0.92198019802\n",
      "\tauc: 0.964344586692\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 92\n",
      "Train:\n",
      "\tloss: 0.10805620037\n",
      "\tacc: 0.955643564356\n",
      "\tauc: 0.980726112108\n",
      "Val:\n",
      "\tloss: 0.19528825811\n",
      "\tacc: 0.922574257426\n",
      "\tauc: 0.964407186189\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 93\n",
      "Train:\n",
      "\tloss: 0.110263681658\n",
      "\tacc: 0.954257425743\n",
      "\tauc: 0.979757441713\n",
      "Val:\n",
      "\tloss: 0.199767084615\n",
      "\tacc: 0.919801980198\n",
      "\tauc: 0.958628750376\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 94\n",
      "Train:\n",
      "\tloss: 0.112603092034\n",
      "\tacc: 0.952178217822\n",
      "\tauc: 0.979646511084\n",
      "Val:\n",
      "\tloss: 0.198344236996\n",
      "\tacc: 0.918712871287\n",
      "\tauc: 0.960428971118\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 95\n",
      "Train:\n",
      "\tloss: 0.0994450012094\n",
      "\tacc: 0.958316831683\n",
      "\tauc: 0.983458337725\n",
      "Val:\n",
      "\tloss: 0.209080726785\n",
      "\tacc: 0.918316831683\n",
      "\tauc: 0.957058544133\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 96\n",
      "Train:\n",
      "\tloss: 0.105423432742\n",
      "\tacc: 0.959405940594\n",
      "\tauc: 0.982636619498\n",
      "Val:\n",
      "\tloss: 0.19845199858\n",
      "\tacc: 0.920396039604\n",
      "\tauc: 0.960279382817\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 97\n",
      "Train:\n",
      "\tloss: 0.106955552634\n",
      "\tacc: 0.955148514851\n",
      "\tauc: 0.98051332743\n",
      "Val:\n",
      "\tloss: 0.21526496274\n",
      "\tacc: 0.918316831683\n",
      "\tauc: 0.963127202001\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 98\n",
      "Train:\n",
      "\tloss: 0.100853473255\n",
      "\tacc: 0.957821782178\n",
      "\tauc: 0.982780584225\n",
      "Val:\n",
      "\tloss: 0.214022539892\n",
      "\tacc: 0.916336633663\n",
      "\tauc: 0.963715365192\n",
      "\n",
      "\n",
      "\n",
      "EPOCH # 99\n",
      "Train:\n",
      "\tloss: 0.105897248796\n",
      "\tacc: 0.955841584158\n",
      "\tauc: 0.981102095117\n",
      "Val:\n",
      "\tloss: 0.204614548332\n",
      "\tacc: 0.918712871287\n",
      "\tauc: 0.96589644674\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from random import shuffle\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "minibatches_per_epoch = 100\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print('EPOCH #', i)\n",
    "    #training\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    \n",
    "    \n",
    "    ## SHUFFLE DATA\n",
    "    data_tr = list(zip(list(desc_tr), list(title_tr), list(nontext_tr), list(target_tr)))\n",
    "    data_ts = list(zip(list(desc_ts), list(title_ts), list(nontext_ts), list(target_ts)))\n",
    "    shuffle(data_tr)\n",
    "    shuffle(data_ts)\n",
    "    desc_tr, title_tr, nontext_tr, target_tr = [np.asarray(t) for t in zip(*data_tr)]\n",
    "    desc_ts, title_ts, nontext_ts, target_ts = [np.asarray(t) for t in zip(*data_ts)]\n",
    "    \n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_tr,title_tr,nontext_tr,target_tr,batchsize=batch_size,shuffle=False)):\n",
    "        ## FIXME: shuffle=True causes incorrect behaviour\n",
    "        if j > minibatches_per_epoch:break\n",
    "            \n",
    "        loss,pred_probas = train_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "    \n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print(\"Train:\")\n",
    "    print('\\tloss:',b_loss/b_c)\n",
    "    print('\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.))\n",
    "    print('\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred))\n",
    "    # print('\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1))\n",
    "    \n",
    "    #evaluation\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_ts,title_ts,nontext_ts,target_ts,batchsize=batch_size,shuffle=False)):\n",
    "        if j > minibatches_per_epoch: break\n",
    "        loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print(\"Val:\")\n",
    "    print('\\tloss:',b_loss/b_c)\n",
    "    print('\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.))\n",
    "    print('\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred))\n",
    "    print('\\n\\n')\n",
    "    # print('\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are seeing this, it's time to backup your notebook. No, really, 'tis too easy to mess up everything without noticing. \n"
     ]
    }
   ],
   "source": [
    "print(\"If you are seeing this, it's time to backup your notebook. No, really, 'tis too easy to mess up everything without noticing. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation\n",
    "\n",
    "Evaluate network over the entire test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "\tloss: 0.204054749427\n",
      "\tacc: 0.920047619048\n",
      "\tauc: 0.962494573913\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "epoch_y_true = []\n",
    "epoch_y_pred = []\n",
    "\n",
    "b_c = b_loss = 0\n",
    "for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "    iterate_minibatches(desc_ts,title_ts,nontext_tr,target_ts,batchsize=batch_size,shuffle=False)):\n",
    "    loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "\n",
    "    b_loss += loss\n",
    "    b_c +=1\n",
    "\n",
    "    epoch_y_true.append(b_y)\n",
    "    epoch_y_pred.append(pred_probas)\n",
    "\n",
    "\n",
    "epoch_y_true = np.concatenate(epoch_y_true)\n",
    "epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "\n",
    "final_accuracy = accuracy_score(epoch_y_true,epoch_y_pred>0)\n",
    "final_auc = roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "# final_apatk = APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "\n",
    "print(\"Scores:\")\n",
    "print('\\tloss:',b_loss/b_c)\n",
    "print('\\tacc:',final_accuracy)\n",
    "print('\\tauc:',final_auc)\n",
    "# print '\\tap@k:',final_apatk\n",
    "# score(final_accuracy,final_auc,final_apatk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Main task\n",
    "* https://goo.gl/forms/eJwIeAbjxzVuo6vn1\n",
    "* Feel like Le'Cun:\n",
    "    * accuracy > 0.95\n",
    "    * AUC > 0.97\n",
    "    * Average Precision at (test sample size * 0.025) > 0.99\n",
    "    * And perhaps even farther\n",
    "* Casual mode\n",
    "    * accuracy > 0.90\n",
    "    * AUC > 0.95\n",
    "    * Average Precision at (test sample size * 0.025) > 0.92\n",
    "* Remember the training, Luke\n",
    "    * Dropout, regularization\n",
    "    * Mommentum, RMSprop, ada*\n",
    "    * etc etc etc\n",
    "    * If you have background in texts, there may be a way to improve tokenizer, add some lemmatization, etc etc.\n",
    "    * In case you know how not to shoot yourself in the foot with RNNs, they too may be of some use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
